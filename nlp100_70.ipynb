{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** データの入手・整形 ****\n",
    "\n",
    "文に関する極性分析の正解データを用い，以下の要領で正解データ（sentiment.txt）を作成せよ．\n",
    "\n",
    "rt-polarity.posの各行の先頭に\"+1 \"という文字列を追加する（極性ラベル\"+1\"とスペースに続けて肯定的な文の内容が続く）\n",
    "rt-polarity.negの各行の先頭に\"-1 \"という文字列を追加する（極性ラベル\"-1\"とスペースに続けて否定的な文の内容が続く）\n",
    "上述1と2の内容を結合（concatenate）し，行をランダムに並び替える\n",
    "\n",
    "sentiment.txtを作成したら，正例（肯定的な文）の数と負例（否定的な文）の数を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import codecs\n",
    "import random\n",
    "\n",
    "fname_pos = 'nlp100data/rt-polaritydata/rt-polarity.pos'\n",
    "fname_neg = 'nlp100data/rt-polaritydata/rt-polarity.neg'\n",
    "fname_smt = 'nlp100data/sentiment.txt'\n",
    "fencoding = 'cp1252'        # Windows-1252らしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ポジティブデータの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(fname_pos, 'r', fencoding) as file_pos:\n",
    "    result.extend(['+1 {}'.format(line.strip()) for line in file_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of postive sentences is {}\".format(len(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_neg = []\n",
    "with codecs.open(fname_neg, 'r', fencoding) as file_neg:\n",
    "    result_neg.extend(['-1 {}'.format(line.strip()) for line in file_neg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of negative sentences is {}\".format(len(result_neg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.extend(result_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total number of sentences is {}\".format(len(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シャッフル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "書き出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(fname_smt, 'w', fencoding) as file_out:\n",
    "    print(*result, sep='\\n', file=file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ストップワード\n",
    "\n",
    "英語のストップワードのリスト（ストップリスト）を適当に作成せよ．\n",
    "\n",
    "さらに，引数に与えられた単語（文字列）がストップリストに含まれている場合は真，それ以外は偽を返す関数を実装せよ．\n",
    "\n",
    "さらに，その関数に対するテストを記述せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ストップワードのリスト  http://xpo6.com/list-of-english-stop-words/ のCSV Formatより"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = (\n",
    "    'a,able,about,across,after,all,almost,also,am,among,an,and,any,are,'\n",
    "    'as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,'\n",
    "    'either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,'\n",
    "    'him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,'\n",
    "    'likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,'\n",
    "    'on,only,or,other,our,own,rather,said,say,says,she,should,since,so,'\n",
    "    'some,than,that,the,their,them,then,there,these,they,this,tis,to,too,'\n",
    "    'twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,'\n",
    "    'will,with,would,yet,you,your').lower().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stopword(str):\n",
    "    '''文字がストップワードかどうかを返す\n",
    "    大小文字は同一視する\n",
    "\n",
    "    戻り値：\n",
    "    ストップワードならTrue、違う場合はFalse\n",
    "    '''\n",
    "    return str.lower() in stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-14282b1f4af6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mis_stopword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tokyo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert is_stopword(\"Tokyo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_stopword(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 素性抽出\n",
    "\n",
    "極性分析に有用そうな素性を各自で設計し，学習データから素性を抽出せよ．\n",
    "\n",
    "素性としては，レビューからストップワードを除去し，各単語をステミング処理したものが最低限のベースラインとなるであろう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** coreNLPを使ったほうがよさそう。nlp100_50.ipynbの先頭を踏襲すればよい（？）****\n",
    "\n",
    "https://github.com/Lynten/stanford-corenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(fname_smt, 'r', fencoding) as rf:\n",
    "    for i , l in enumerate(rf):\n",
    "        for w in l[3:].split(\" \"):\n",
    "            print(w.strip())\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corenlp = StanfordCoreNLP(r'/home/toshinao/Tools/stanford-corenlp-full-2018-02-27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "props={'annotators': 'lemma','pipelineLanguage':'en','outputFormat':'xml'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmls = list()\n",
    "with codecs.open(fname_smt, 'r', fencoding) as rf:\n",
    "    for l in rf:\n",
    "        run_xml = corenlp.annotate(l[3:] , properties=props)\n",
    "        xmls.append(run_xml)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xmls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"x\" not in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in xmls:\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    for x in soup.find_all(\"lemma\"):\n",
    "        y = x.get_text()\n",
    "        if y not in stop_words:\n",
    "            word_counter.update([y])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [word for word, count in word_counter.items() if count >= 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of seletcted features is 3439\n"
     ]
    }
   ],
   "source": [
    "print(\"number of seletcted features is {}\".format(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['play',\n",
       " 'droll',\n",
       " 'hear',\n",
       " 'worry',\n",
       " 'promise',\n",
       " 'conclusion',\n",
       " 'nonsense',\n",
       " 'pumpkin',\n",
       " 'minor',\n",
       " 'unintentionally']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_features = \"nlp100data/features.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(fname_features, 'w', fencoding) as file_out:\n",
    "    print(*features, sep='\\n', file=file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_features():\n",
    "    '''features.txtを読み込み、素性をインデックスに変換するための辞書を作成\n",
    "    インデックスの値は1ベースで、features.txtにおける行番号と一致する。\n",
    "\n",
    "    戻り値：\n",
    "    素性をインデックスに変換する辞書\n",
    "    '''\n",
    "    with codecs.open(fname_features, 'r', fencoding) as file_in:\n",
    "        return [l.strip() for l in file_in]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git commit -a -m \"from notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = set()\n",
    "\n",
    "for x in xmls:\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    for x in soup.find_all(\"lemma\"):\n",
    "        y = x.get_text()\n",
    "        if y not in stop_words:\n",
    "            features.add(y)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in soup.find_all(\"lemma\"):\n",
    "    print(x.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_xml = corenlp.annotate(l, properties=props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corenlp.parse(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Lynten/stanford-corenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "props={'annotators': 'tokenize,ssplit,pos','pipelineLanguage':'en','outputFormat':'xml'}\n",
    "print(corenlp.annotate(l, properties=props))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習\n",
    "72で抽出した素性を用いて，ロジスティック回帰モデルを学習せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer as CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = load_dict_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CV(vocabulary=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x3439 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(features[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(cv.transform([\"shibuya\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sum_list = []\n",
    "for x in xmls:\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    lemmas = list()\n",
    "    for x in soup.find_all(\"lemma\"):\n",
    "        xt = x.get_text()\n",
    "        if xt not in stop_words:\n",
    "            lemmas.append(xt)\n",
    "    token_matrix = cv.transform(lemmas).toarray()\n",
    "    token_sum = token_matrix.sum(axis = 0).astype(float)\n",
    "    token_sum_list.append(token_sum.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sum_matrix = np.array(token_sum_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10662, 3439)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_sum_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(fname_smt, 'r', fencoding) as rf:\n",
    "    y = [float(l[0:2]) for l in rf ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10662,)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ailaby.com/logistic_reg/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X = token_sum_matrix , y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87225661226786722"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X=token_sum_matrix , y = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 予測\n",
    "\n",
    "73で学習したロジスティック回帰モデルを用い，与えられた文の極性ラベル（正例なら\"+1\"，負例なら\"-1\"）と，その予測確率を計算するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = lr.predict(X = token_sum_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35716411,  0.550107  , -0.22356707, ..., -0.38271609,\n",
       "        -0.82514424,  0.50568172]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.27312972])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy_pred2 = 1/ ( 1 + np.exp(-lr.intercept_ -token_sum_matrix.dot(np.transpose(lr.coef_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = [1 if x > 0.5 else -1 for x in fy_pred2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(y_pred1[i] , fy_pred2[i]) for i in range(len(y_pred2)) if y_pred2[i] != y_pred1[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "X_0 = np.random.multivariate_normal( [2,2],  [[2,0],[0,2]],  50 )\n",
    "y_0 = np.zeros(len(X_0))\n",
    " \n",
    "X_1 = np.random.multivariate_normal( [6,7],  [[3,0],[0,3]],  50 )\n",
    "y_1 = np.ones(len(X_1))\n",
    " \n",
    "X = np.vstack((X_0, X_1))\n",
    "ytmp = np.append(y_0, y_1)\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ytmp, test_size=0.3)\n",
    " \n",
    "# 特徴データを標準化(平均 0、標準偏差 1)\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://note.nkmk.me/python-numpy-eye-identity-one-hot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(10)[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xmls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(x, 'lxml')\n",
    "lemmas = list()\n",
    "for x in soup.find_all(\"lemma\"):\n",
    "    y = x.get_text()\n",
    "    if y not in stop_words:\n",
    "        lemmas.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = cv.transform(lemmas).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.sum(axis = 0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master b352032] from notebook\n",
      " 1 file changed, 142 insertions(+), 94 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "git commit -a -m\"from notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: push.default is unset; its implicit value has changed in\n",
      "Git 2.0 from 'matching' to 'simple'. To squelch this message\n",
      "and maintain the traditional behavior, use:\n",
      "\n",
      "  git config --global push.default matching\n",
      "\n",
      "To squelch this message and adopt the new behavior now, use:\n",
      "\n",
      "  git config --global push.default simple\n",
      "\n",
      "When push.default is set to 'matching', git will push local branches\n",
      "to the remote branches that already exist with the same name.\n",
      "\n",
      "Since Git 2.0, Git defaults to the more conservative 'simple'\n",
      "behavior, which only pushes the current branch to the corresponding\n",
      "remote branch that 'git pull' uses to update the current branch.\n",
      "\n",
      "See 'git help config' and search for 'push.default' for further information.\n",
      "(the 'simple' mode was introduced in Git 1.7.11. Use the similar mode\n",
      "'current' instead of 'simple' if you sometimes use older versions of Git)\n",
      "\n",
      "fatal: could not read Username for 'https://github.com': No such device or address\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 素性の重み\n",
    "73で学習したロジスティック回帰モデルの中で，重みの高い素性トップ10と，重みの低い素性トップ10を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10662, 3439)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_sum_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sum_summary = token_sum_matrix.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_order = token_sum_summary.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[789,\n",
       " 483,\n",
       " 646,\n",
       " 3066,\n",
       " 2129,\n",
       " 724,\n",
       " 107,\n",
       " 3342,\n",
       " 1330,\n",
       " 2331,\n",
       " 220,\n",
       " 880,\n",
       " 2546,\n",
       " 2238,\n",
       " 3096,\n",
       " 511,\n",
       " 630,\n",
       " 2167,\n",
       " 3147,\n",
       " 1514,\n",
       " 2012,\n",
       " 1341,\n",
       " 1521,\n",
       " 2053,\n",
       " 2652,\n",
       " 3057,\n",
       " 1623,\n",
       " 1070,\n",
       " 383,\n",
       " 1492,\n",
       " 479,\n",
       " 2272,\n",
       " 685,\n",
       " 1290,\n",
       " 844,\n",
       " 2499,\n",
       " 3244,\n",
       " 436,\n",
       " 1461,\n",
       " 161,\n",
       " 2308,\n",
       " 3246,\n",
       " 2699,\n",
       " 1664,\n",
       " 1471,\n",
       " 2804,\n",
       " 2915,\n",
       " 1662,\n",
       " 2909,\n",
       " 3243,\n",
       " 3284,\n",
       " 657,\n",
       " 2734,\n",
       " 2524,\n",
       " 2686,\n",
       " 1811,\n",
       " 2142,\n",
       " 2141,\n",
       " 1924,\n",
       " 1650,\n",
       " 1952,\n",
       " 752,\n",
       " 354,\n",
       " 563,\n",
       " 2631,\n",
       " 2349,\n",
       " 2400,\n",
       " 1549,\n",
       " 3235,\n",
       " 2062,\n",
       " 2844,\n",
       " 905,\n",
       " 1197,\n",
       " 2855,\n",
       " 2600,\n",
       " 2385,\n",
       " 1186,\n",
       " 2194,\n",
       " 932,\n",
       " 2858,\n",
       " 2602,\n",
       " 1382,\n",
       " 591,\n",
       " 3031,\n",
       " 2369,\n",
       " 1898,\n",
       " 1587,\n",
       " 763,\n",
       " 1730,\n",
       " 2378,\n",
       " 1375,\n",
       " 13,\n",
       " 3377,\n",
       " 2083,\n",
       " 3017,\n",
       " 2931,\n",
       " 1611,\n",
       " 2505,\n",
       " 547,\n",
       " 1405,\n",
       " 2577,\n",
       " 2216,\n",
       " 1204,\n",
       " 3257,\n",
       " 2568,\n",
       " 1782,\n",
       " 3370,\n",
       " 2279,\n",
       " 3355,\n",
       " 1949,\n",
       " 1344,\n",
       " 3364,\n",
       " 2579,\n",
       " 1954,\n",
       " 301,\n",
       " 2005,\n",
       " 3058,\n",
       " 697,\n",
       " 2517,\n",
       " 2591,\n",
       " 2510,\n",
       " 3366,\n",
       " 2571,\n",
       " 418,\n",
       " 687,\n",
       " 1350,\n",
       " 1352,\n",
       " 754,\n",
       " 296,\n",
       " 1763,\n",
       " 2508,\n",
       " 2289,\n",
       " 1381,\n",
       " 3099,\n",
       " 3004,\n",
       " 1815,\n",
       " 2951,\n",
       " 2526,\n",
       " 2538,\n",
       " 715,\n",
       " 1084,\n",
       " 1962,\n",
       " 2209,\n",
       " 1801,\n",
       " 356,\n",
       " 1366,\n",
       " 761,\n",
       " 2211,\n",
       " 1968,\n",
       " 2941,\n",
       " 729,\n",
       " 3294,\n",
       " 730,\n",
       " 311,\n",
       " 1320,\n",
       " 767,\n",
       " 1124,\n",
       " 1365,\n",
       " 2585,\n",
       " 3237,\n",
       " 305,\n",
       " 1309,\n",
       " 2529,\n",
       " 2535,\n",
       " 2547,\n",
       " 768,\n",
       " 389,\n",
       " 2271,\n",
       " 3006,\n",
       " 2596,\n",
       " 3062,\n",
       " 385,\n",
       " 739,\n",
       " 308,\n",
       " 1068,\n",
       " 2474,\n",
       " 2292,\n",
       " 3217,\n",
       " 546,\n",
       " 2410,\n",
       " 618,\n",
       " 1203,\n",
       " 1205,\n",
       " 2413,\n",
       " 2346,\n",
       " 3330,\n",
       " 2416,\n",
       " 621,\n",
       " 617,\n",
       " 1210,\n",
       " 3314,\n",
       " 1880,\n",
       " 625,\n",
       " 3334,\n",
       " 2422,\n",
       " 1877,\n",
       " 2423,\n",
       " 626,\n",
       " 2425,\n",
       " 1221,\n",
       " 521,\n",
       " 1212,\n",
       " 1888,\n",
       " 551,\n",
       " 3220,\n",
       " 593,\n",
       " 1897,\n",
       " 590,\n",
       " 2372,\n",
       " 2374,\n",
       " 1896,\n",
       " 1178,\n",
       " 1184,\n",
       " 2365,\n",
       " 1185,\n",
       " 2382,\n",
       " 576,\n",
       " 2362,\n",
       " 1190,\n",
       " 1177,\n",
       " 2360,\n",
       " 1193,\n",
       " 1194,\n",
       " 1173,\n",
       " 2356,\n",
       " 2398,\n",
       " 3322,\n",
       " 1170,\n",
       " 554,\n",
       " 553,\n",
       " 1222,\n",
       " 519,\n",
       " 2431,\n",
       " 628,\n",
       " 1149,\n",
       " 2462,\n",
       " 2463,\n",
       " 2966,\n",
       " 1828,\n",
       " 2320,\n",
       " 3345,\n",
       " 3347,\n",
       " 1934,\n",
       " 775,\n",
       " 661,\n",
       " 2476,\n",
       " 1272,\n",
       " 1274,\n",
       " 2479,\n",
       " 1277,\n",
       " 449,\n",
       " 2997,\n",
       " 1821,\n",
       " 670,\n",
       " 3093,\n",
       " 1941,\n",
       " 1287,\n",
       " 1289,\n",
       " 429,\n",
       " 1266,\n",
       " 2953,\n",
       " 1150,\n",
       " 3225,\n",
       " 1228,\n",
       " 2340,\n",
       " 513,\n",
       " 2437,\n",
       " 1858,\n",
       " 1856,\n",
       " 3341,\n",
       " 2438,\n",
       " 636,\n",
       " 1240,\n",
       " 499,\n",
       " 3210,\n",
       " 1846,\n",
       " 640,\n",
       " 1844,\n",
       " 1912,\n",
       " 1916,\n",
       " 488,\n",
       " 2450,\n",
       " 1836,\n",
       " 1258,\n",
       " 2452,\n",
       " 2969,\n",
       " 647,\n",
       " 1922,\n",
       " 474,\n",
       " 776,\n",
       " 3101,\n",
       " 1742,\n",
       " 2908,\n",
       " 1477,\n",
       " 1478,\n",
       " 1651,\n",
       " 1004,\n",
       " 1482,\n",
       " 2738,\n",
       " 2138,\n",
       " 2136,\n",
       " 1483,\n",
       " 863,\n",
       " 2903,\n",
       " 3273,\n",
       " 2041,\n",
       " 870,\n",
       " 1646,\n",
       " 2130,\n",
       " 997,\n",
       " 1498,\n",
       " 2761,\n",
       " 877,\n",
       " 2901,\n",
       " 2766,\n",
       " 1475,\n",
       " 2723,\n",
       " 3043,\n",
       " 2721,\n",
       " 2690,\n",
       " 1446,\n",
       " 1448,\n",
       " 188,\n",
       " 1674,\n",
       " 2153,\n",
       " 1673,\n",
       " 3400,\n",
       " 176,\n",
       " 2703,\n",
       " 841,\n",
       " 2767,\n",
       " 2150,\n",
       " 169,\n",
       " 2707,\n",
       " 847,\n",
       " 1668,\n",
       " 3276,\n",
       " 1384,\n",
       " 2037,\n",
       " 1007,\n",
       " 3158,\n",
       " 1663,\n",
       " 2718,\n",
       " 170,\n",
       " 2158,\n",
       " 2768,\n",
       " 2770,\n",
       " 2087,\n",
       " 1603,\n",
       " 2065,\n",
       " 1602,\n",
       " 1600,\n",
       " 31,\n",
       " 3027,\n",
       " 2850,\n",
       " 2852,\n",
       " 2854,\n",
       " 3128,\n",
       " 2085,\n",
       " 18,\n",
       " 15,\n",
       " 2867,\n",
       " 2081,\n",
       " 3139,\n",
       " 3130,\n",
       " 2067,\n",
       " 2874,\n",
       " 3131,\n",
       " 2070,\n",
       " 1583,\n",
       " 2832,\n",
       " 921,\n",
       " 920,\n",
       " 2825,\n",
       " 2123,\n",
       " 2044,\n",
       " 1631,\n",
       " 94,\n",
       " 3266,\n",
       " 2109,\n",
       " 1516,\n",
       " 2796,\n",
       " 1627,\n",
       " 1625,\n",
       " 3422,\n",
       " 101,\n",
       " 1622,\n",
       " 1620,\n",
       " 972,\n",
       " 971,\n",
       " 2095,\n",
       " 908,\n",
       " 1615,\n",
       " 914,\n",
       " 1614,\n",
       " 2059,\n",
       " 1542,\n",
       " 1612,\n",
       " 2805,\n",
       " 1034,\n",
       " 2146,\n",
       " 200,\n",
       " 813,\n",
       " 1431,\n",
       " 3382,\n",
       " 2014,\n",
       " 263,\n",
       " 2658,\n",
       " 1045,\n",
       " 1578,\n",
       " 3389,\n",
       " 2672,\n",
       " 213,\n",
       " 267,\n",
       " 1049,\n",
       " 3047,\n",
       " 2171,\n",
       " 270,\n",
       " 3116,\n",
       " 3111,\n",
       " 798,\n",
       " 1426,\n",
       " 226,\n",
       " 225,\n",
       " 224,\n",
       " 795,\n",
       " 1685,\n",
       " 810,\n",
       " 3390,\n",
       " 1427,\n",
       " 2665,\n",
       " 794,\n",
       " 219,\n",
       " 2925,\n",
       " 231,\n",
       " 211,\n",
       " 1681,\n",
       " 2623,\n",
       " 1738,\n",
       " 1708,\n",
       " 1678,\n",
       " 286,\n",
       " 2201,\n",
       " 2648,\n",
       " 2199,\n",
       " 2618,\n",
       " 1052,\n",
       " 203,\n",
       " 802,\n",
       " 2192,\n",
       " 2927,\n",
       " 2638,\n",
       " 1438,\n",
       " 206,\n",
       " 2172,\n",
       " 1418,\n",
       " 1720,\n",
       " 241,\n",
       " 272,\n",
       " 1436,\n",
       " 2918,\n",
       " 2177,\n",
       " 2112,\n",
       " 892,\n",
       " 2344,\n",
       " 3072,\n",
       " 3037,\n",
       " 2174,\n",
       " 2098,\n",
       " 3315,\n",
       " 2107,\n",
       " 2100,\n",
       " 2178,\n",
       " 3250,\n",
       " 750,\n",
       " 3032,\n",
       " 976,\n",
       " 2000,\n",
       " 918,\n",
       " 2094,\n",
       " 605,\n",
       " 2208,\n",
       " 929,\n",
       " 930,\n",
       " 2364,\n",
       " 2084,\n",
       " 784,\n",
       " 3316,\n",
       " 950,\n",
       " 771,\n",
       " 3016,\n",
       " 2207,\n",
       " 947,\n",
       " 1056,\n",
       " 2366,\n",
       " 3054,\n",
       " 927,\n",
       " 608,\n",
       " 2090,\n",
       " 969,\n",
       " 3026,\n",
       " 1048,\n",
       " 3255,\n",
       " 1062,\n",
       " 1902,\n",
       " 749,\n",
       " 791,\n",
       " 790,\n",
       " 612,\n",
       " 924,\n",
       " 765,\n",
       " 2190,\n",
       " 792,\n",
       " 2113,\n",
       " 1985,\n",
       " 986,\n",
       " 1020,\n",
       " 2031,\n",
       " 3064,\n",
       " 817,\n",
       " 3002,\n",
       " 2264,\n",
       " 1035,\n",
       " 683,\n",
       " 1010,\n",
       " 1939,\n",
       " 2253,\n",
       " 2311,\n",
       " 669,\n",
       " 718,\n",
       " 665,\n",
       " 2317,\n",
       " 2303,\n",
       " 836,\n",
       " 3279,\n",
       " 818,\n",
       " 1033,\n",
       " 1117,\n",
       " 2163,\n",
       " 1957,\n",
       " 826,\n",
       " 2021,\n",
       " 3298,\n",
       " 703,\n",
       " 704,\n",
       " 829,\n",
       " 830,\n",
       " 706,\n",
       " 3302,\n",
       " 2287,\n",
       " 834,\n",
       " 3063,\n",
       " 3231,\n",
       " 2249,\n",
       " 2050,\n",
       " 1965,\n",
       " 1137,\n",
       " 1081,\n",
       " 2124,\n",
       " 3223,\n",
       " 879,\n",
       " 2275,\n",
       " 881,\n",
       " 1998,\n",
       " 875,\n",
       " 2335,\n",
       " 2173,\n",
       " 633,\n",
       " 1164,\n",
       " 1909,\n",
       " 804,\n",
       " 3270,\n",
       " 2045,\n",
       " 1072,\n",
       " 2042,\n",
       " 645,\n",
       " 1043,\n",
       " 2248,\n",
       " 1967,\n",
       " 3042,\n",
       " 1141,\n",
       " 855,\n",
       " 2247,\n",
       " 856,\n",
       " 732,\n",
       " 2140,\n",
       " 1148,\n",
       " 1977,\n",
       " 1088,\n",
       " 2328,\n",
       " 1002,\n",
       " 2134,\n",
       " 1040,\n",
       " 871,\n",
       " 663,\n",
       " 3317,\n",
       " 2461,\n",
       " 594,\n",
       " 228,\n",
       " 1692,\n",
       " 3173,\n",
       " 232,\n",
       " 1698,\n",
       " 1703,\n",
       " 1432,\n",
       " 2649,\n",
       " 1413,\n",
       " 1715,\n",
       " 252,\n",
       " 1407,\n",
       " 255,\n",
       " 1406,\n",
       " 2924,\n",
       " 258,\n",
       " 2920,\n",
       " 3168,\n",
       " 1456,\n",
       " 3401,\n",
       " 2913,\n",
       " 1455,\n",
       " 1453,\n",
       " 1449,\n",
       " 2882,\n",
       " 2697,\n",
       " 2693,\n",
       " 3119,\n",
       " 193,\n",
       " 1444,\n",
       " 198,\n",
       " 199,\n",
       " 190,\n",
       " 172,\n",
       " 3380,\n",
       " 266,\n",
       " 1755,\n",
       " 3184,\n",
       " 317,\n",
       " 2586,\n",
       " 326,\n",
       " 3100,\n",
       " 1371,\n",
       " 1360,\n",
       " 2573,\n",
       " 1764,\n",
       " 2570,\n",
       " 342,\n",
       " 2569,\n",
       " 344,\n",
       " 1761,\n",
       " 3437,\n",
       " 2594,\n",
       " 307,\n",
       " 2630,\n",
       " 269,\n",
       " 1400,\n",
       " 1398,\n",
       " 1395,\n",
       " 1726,\n",
       " 3183,\n",
       " 1729,\n",
       " 285,\n",
       " 2613,\n",
       " 292,\n",
       " 294,\n",
       " 304,\n",
       " 2368,\n",
       " 1737,\n",
       " 345,\n",
       " 1458,\n",
       " 1460,\n",
       " 2814,\n",
       " 1617,\n",
       " 1536,\n",
       " 1619,\n",
       " 2807,\n",
       " 61,\n",
       " 54,\n",
       " 63,\n",
       " 68,\n",
       " 69,\n",
       " 2894,\n",
       " 1524,\n",
       " 77,\n",
       " 80,\n",
       " 1621,\n",
       " 2793,\n",
       " 3428,\n",
       " 50,\n",
       " 1575,\n",
       " 2876,\n",
       " 1591,\n",
       " 2887,\n",
       " 2861,\n",
       " 20,\n",
       " 51,\n",
       " 24,\n",
       " 3431,\n",
       " 1548,\n",
       " 2830,\n",
       " 3126,\n",
       " 2822,\n",
       " 48,\n",
       " 3433,\n",
       " 1459,\n",
       " 1515,\n",
       " 87,\n",
       " 2745,\n",
       " 2744,\n",
       " 2743,\n",
       " 2741,\n",
       " 2739,\n",
       " 1481,\n",
       " 1486,\n",
       " 1654,\n",
       " 1476,\n",
       " 1660,\n",
       " 157,\n",
       " 2714,\n",
       " 159,\n",
       " 2710,\n",
       " 142,\n",
       " 2787,\n",
       " 2751,\n",
       " 2753,\n",
       " 2786,\n",
       " 89,\n",
       " 1508,\n",
       " 1505,\n",
       " 2777,\n",
       " 3149,\n",
       " 1648,\n",
       " 2769,\n",
       " 106,\n",
       " 109,\n",
       " 113,\n",
       " 2759,\n",
       " 115,\n",
       " 2757,\n",
       " 1500,\n",
       " 348,\n",
       " 2597,\n",
       " 2071,\n",
       " 1229,\n",
       " 1225,\n",
       " 1818,\n",
       " 1869,\n",
       " 2502,\n",
       " 2952,\n",
       " 1294,\n",
       " 423,\n",
       " 1872,\n",
       " 1878,\n",
       " 420,\n",
       " 419,\n",
       " 3094,\n",
       " 2511,\n",
       " 2513,\n",
       " 3213,\n",
       " 3332,\n",
       " 3078,\n",
       " 2520,\n",
       " 3076,\n",
       " 2415,\n",
       " 1304,\n",
       " 3327,\n",
       " 2494,\n",
       " 2408,\n",
       " 2436,\n",
       " 505,\n",
       " 1835,\n",
       " 1256,\n",
       " 2456,\n",
       " 1832,\n",
       " 3262,\n",
       " 470,\n",
       " 1829,\n",
       " 1837,\n",
       " 2471,\n",
       " 461,\n",
       " 3348,\n",
       " 2475,\n",
       " 490,\n",
       " 1275,\n",
       " 2480,\n",
       " 1249,\n",
       " 494,\n",
       " 2958,\n",
       " 446,\n",
       " 1851,\n",
       " 443,\n",
       " 2489,\n",
       " 2490,\n",
       " 1283,\n",
       " 400,\n",
       " 1302,\n",
       " 1262,\n",
       " 2394,\n",
       " 3095,\n",
       " 2944,\n",
       " 566,\n",
       " 1324,\n",
       " 2391,\n",
       " 2979,\n",
       " 2380,\n",
       " 2397,\n",
       " 1328,\n",
       " 1794,\n",
       " 1334,\n",
       " 1800,\n",
       " 1795,\n",
       " 2383,\n",
       " 1189,\n",
       " 2946,\n",
       " 570,\n",
       " 1810,\n",
       " 2539,\n",
       " 2541,\n",
       " 561,\n",
       " 2405,\n",
       " 2950,\n",
       " 1808,\n",
       " 2976,\n",
       " 1198,\n",
       " 583,\n",
       " 2938,\n",
       " 1804,\n",
       " 1805,\n",
       " 362,\n",
       " 384,\n",
       " 2564,\n",
       " 2551,\n",
       " 2948,\n",
       " 1890,\n",
       " 388,\n",
       " 2536,\n",
       " 1573,\n",
       " 1499,\n",
       " 1182,\n",
       " 1576,\n",
       " 1247,\n",
       " 1592,\n",
       " 1642,\n",
       " 3142,\n",
       " 1597,\n",
       " 3088,\n",
       " 1199,\n",
       " 1243,\n",
       " 970,\n",
       " 1171,\n",
       " 3252,\n",
       " 1533,\n",
       " 1647,\n",
       " 1168,\n",
       " 1903,\n",
       " 3251,\n",
       " 977,\n",
       " 2060,\n",
       " 1605,\n",
       " 1554,\n",
       " 1855,\n",
       " 1236,\n",
       " 3145,\n",
       " 1237,\n",
       " 1630,\n",
       " 1510,\n",
       " 1509,\n",
       " 993,\n",
       " 1910,\n",
       " 1160,\n",
       " 3222,\n",
       " 1784,\n",
       " 1001,\n",
       " 1057,\n",
       " 1105,\n",
       " 1744,\n",
       " 1961,\n",
       " 1393,\n",
       " 1051,\n",
       " 1746,\n",
       " 3238,\n",
       " 1312,\n",
       " 1717,\n",
       " 1116,\n",
       " 3202,\n",
       " 1046,\n",
       " 1305,\n",
       " 1111,\n",
       " 1409,\n",
       " 1103,\n",
       " 1325,\n",
       " 1787,\n",
       " 1788,\n",
       " 1078,\n",
       " 1974,\n",
       " 1973,\n",
       " 3188,\n",
       " 1964,\n",
       " 3186,\n",
       " 1757,\n",
       " 1064,\n",
       " 1063,\n",
       " 1333,\n",
       " 3185,\n",
       " 3197,\n",
       " 1096,\n",
       " 1411,\n",
       " 1119,\n",
       " 3203,\n",
       " 1019,\n",
       " 1083,\n",
       " 1457,\n",
       " 2032,\n",
       " 1135,\n",
       " 1136,\n",
       " 1134,\n",
       " 3160,\n",
       " 1465,\n",
       " 1271,\n",
       " 1142,\n",
       " 1927,\n",
       " 1263,\n",
       " 1489,\n",
       " 1280,\n",
       " 2028,\n",
       " 1937,\n",
       " 3164,\n",
       " 3114,\n",
       " 1300,\n",
       " 1694,\n",
       " 1684,\n",
       " 1038,\n",
       " 1680,\n",
       " 1295,\n",
       " 1125,\n",
       " 1031,\n",
       " 1288,\n",
       " 2020,\n",
       " 3206,\n",
       " 1130,\n",
       " 1025,\n",
       " 1024,\n",
       " 1000,\n",
       " 3092,\n",
       " 1441,\n",
       " 2073,\n",
       " 434,\n",
       " 2491,\n",
       " 440,\n",
       " 453,\n",
       " 2962,\n",
       " 2477,\n",
       " 2473,\n",
       " 469,\n",
       " 473,\n",
       " 477,\n",
       " 486,\n",
       " 2449,\n",
       " 2971,\n",
       " 2441,\n",
       " 506,\n",
       " 2500,\n",
       " 3340,\n",
       " 430,\n",
       " 416,\n",
       " 349,\n",
       " 3363,\n",
       " 352,\n",
       " 370,\n",
       " 372,\n",
       " 374,\n",
       " 375,\n",
       " 377,\n",
       " 2542,\n",
       " 394,\n",
       " 2528,\n",
       " 2527,\n",
       " 403,\n",
       " 2522,\n",
       " 2516,\n",
       " 422,\n",
       " 338,\n",
       " 518,\n",
       " 2424,\n",
       " 658,\n",
       " 2318,\n",
       " 666,\n",
       " 2313,\n",
       " 3306,\n",
       " 2301,\n",
       " 2293,\n",
       " 688,\n",
       " 2280,\n",
       " 698,\n",
       " 2276,\n",
       " 705,\n",
       " 2273,\n",
       " 716,\n",
       " 2252,\n",
       " 655,\n",
       " 2429,\n",
       " ...]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_order.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features = [feature_names[i] for i in token_order.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " 'well-intentioned',\n",
       " 'so-so',\n",
       " 'fast-paced',\n",
       " 'gross-out',\n",
       " 'u',\n",
       " 'self-indulgent',\n",
       " \"'70s\",\n",
       " '!',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted_features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['up',\n",
       " 'out',\n",
       " 'time',\n",
       " 'character',\n",
       " 'story',\n",
       " 'more',\n",
       " 'one',\n",
       " 'make',\n",
       " 'movie',\n",
       " 'film']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_features[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.,     0.,     0., ...,   797.,  1602.,  1802.])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_sum_summary[token_sum_summary.argsort()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 372a8de] done 75\n",
      " 1 file changed, 1167 insertions(+), 17 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git commit -a -m \"done 75\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ラベル付け\n",
    "学習データに対してロジスティック回帰モデルを適用し，正解のラベル，予測されたラベル，予測確率をタブ区切り形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "out6 = [\"{}\\t{}\\t{}\".format(y[i] , y_pred2[i] , max(fy_pred2[i,0] , 1-fy_pred2[i,0])) for i in range(len(y))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\t-1\t0.633762083074387\n",
      "-1.0\t1\t0.525303131220722\n",
      "-1.0\t-1\t0.6472735732404634\n",
      "-1.0\t-1\t0.8835594420620706\n",
      "-1.0\t-1\t0.8016856898511299\n",
      "1.0\t1\t0.9010667407594842\n",
      "1.0\t-1\t0.7583124365637459\n",
      "1.0\t1\t0.5558477883619057\n",
      "1.0\t-1\t0.5214795540802553\n",
      "-1.0\t-1\t0.8734910496169361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(x) for  x in out6[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36623791692561303"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fy_pred2[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
