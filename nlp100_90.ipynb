{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git add nlp100_90.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git commit -a -m \"added nlp100_90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "conda install word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** 0. word2vecによる学習 ****\n",
    "\n",
    "81で作成したコーパスに対してword2vecを適用し，単語ベクトルを学習せよ．さらに，学習した単語ベクトルの形式を変換し，86-89のプログラムを動かせ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[python word2vecパッケージの公式ページ](https://github.com/danielfrg/word2vec)\n",
    "\n",
    "[official example](http://nbviewer.jupyter.org/github/danielfrg/word2vec/blob/master/examples/word2vec.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_output81 = \"nlp100data/output81.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_phrases90 = 'nlp100data/phrases90.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_wordvecs90bin = 'nlp100data/wordvecs90.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_wordvecs90 = 'nlp100data/wordvecs90.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file nlp100data/output81.txt\n",
      "Words processed: 11800K     Vocab size: 4364K  \n",
      "Vocab size (unigrams + bigrams): 2372876\n",
      "Words in train file: 11869261\n",
      "Words written: 11800K\r"
     ]
    }
   ],
   "source": [
    "word2vec.word2phrase(fname_output81 , fname_phrases90 , verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file nlp100data/phrases90.txt\n",
      "Vocab size: 105991\n",
      "Words in train file: 11192135\n",
      "Alpha: 0.000019  Progress: 99.94%  Words/thread/sec: 543.23k  "
     ]
    }
   ],
   "source": [
    "word2vec.word2vec(train = fname_phrases90 , output = fname_wordvecs90bin , size = 50 , threads = 4 ,  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.load(fname = fname_wordvecs90bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** 86のword2vec版 ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06594494, -0.06648544, -0.02266973, -0.26417384,  0.0348038 ,\n",
       "        0.16276203, -0.10152841, -0.20559365,  0.11061635, -0.05128405,\n",
       "       -0.1579421 ,  0.18112618, -0.29654896,  0.11253238, -0.17636853,\n",
       "        0.06542736,  0.20164117,  0.07633649,  0.07534473, -0.24391665,\n",
       "       -0.09185803,  0.06577205, -0.01773164, -0.2031363 ,  0.08185295,\n",
       "       -0.02703902, -0.07227903, -0.06967267, -0.11732481, -0.12979949,\n",
       "       -0.14991304, -0.12434923,  0.23231378,  0.16840932,  0.25385424,\n",
       "        0.11206607,  0.08833051, -0.04896447, -0.00366609,  0.30139831,\n",
       "       -0.04291305,  0.04288597,  0.05653698,  0.11127364, -0.17320317,\n",
       "        0.02737914, -0.10143059, -0.04345994, -0.22382653,  0.08549703])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['United_States']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** 87のword2vec版 ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = model['United_States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = model['U.S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine関数の出力は２（逆向き）、１（直行）,0(一致)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity is : 0.13559367595294014\n"
     ]
    }
   ],
   "source": [
    "print(\"cosine similarity is : {}\".format(cosine(v0,v1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** 88のword2vec版 ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices , metrics = model.similar('England')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Scotland', 'France', 'Spain', 'Italy', 'Ireland', 'Germany',\n",
       "       'Athens', 'Norway', 'Wales', 'Denmark'], dtype='<U78')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** 89のword2vec版 ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes, metrics = model.analogy(pos=['Spain', 'Athens'], neg=['Madrid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Scotland', 'France', 'Spain', 'Italy', 'Ireland', 'Germany',\n",
       "       'Athens', 'Norway', 'Wales', 'Denmark'], dtype='<U78')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** sandbox ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.word2vec(train = fname_output81 , output = fname_wordvecs90 , size = 50 , threads = 4 , binary = False , verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git commit -a -m \"doing 90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install word2vec -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(fname_phrases90 , 'r' , 'utf-8') as rf:\n",
    "    for i, l in enumerate(rf):\n",
    "        print(l)\n",
    "        if i > 2:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
